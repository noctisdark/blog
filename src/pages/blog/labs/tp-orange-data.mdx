---
layout: "@layouts/blog/Layout.astro"
title: "Data Mining et Machine Learning avec Orange"
description: "Découverte d'Orange, un logiciel open-source de data mining et machine learning qui offre une interface graphique conviviale pour créer et exécuter des analyses de données. Il permet l'exploration de données, la modélisation prédictive, la visualisation et la communication des résultats."
author: "Majed Abdennadher"
timestamp: 1674091068893
duration: 10
tag: "Lab"
slug: "tp-orange-data"
language: "french"
image: "https://cdn.dribbble.com/users/227882/screenshots/12098623/media/fc0e9edd3b92c0ac5782162f1a515e2e.jpg?compress=1&resize=400x300"
keywords: ["Data mining", "Statistical learning", "Machine learning"]
links: ["tp-suricata"]
---

#### Disclaimer

Au moment où j'ai réalisé le TP, le lien Teams vers le jeu de données `KDD CUP 1999` avait déjà expiré. J'ai donc utilisé une autre source ([kaggle](https://www.kaggle.com/datasets/galaxyh/kdd-cup-1999-data?resource=download&select=kddcup.data_10_percent.gz)).

## Question 1:

Voici le schéma avec lequel nous allons travailler:
![](https://i.imgur.com/Li5VlXd.png)

#### Combien d'instances y a-t-il dans ce jeu de données ? Combien d'attributs y a-t-il ?

Dans `Data Table`, nous observons :
![](https://i.imgur.com/oDfIqZt.png)

#### À votre avis, que signifient le `C` vert et le `N` rouge à côté du nom des attributs ?

Dans `Distributions`, nous observons :
![](https://i.imgur.com/VQk53WT.png)

Le `C` vert et le `N` rouge correspondent au type de l'attribut :

- <code style="color: green;">C</code> pour categorical (catégorique)
- <code style="color: red;">N</code> pour numerical (numérique)

L'attribut `label` correspond à la catégorisation d'une attaque.

#### Que représente l'attribut `label` ?

En regardant les valeurs possible de `label`, nottament `normal`, `dos`, `r2l`. On déduit qu'il s'agit de la catégorization de l'attaque

## Question 2:

Voici la distribution par `label`:

#### Observez la distribution de l'attribut `label`. Quelle classe est majoritaire ?

![](https://i.imgur.com/hACdOS8.png)

La classe majoritaire est `smurf`. En consultant la page [Wikipedia](https://en.wikipedia.org/wiki/Smurf_attack) :
Attaque Smurf, un type d'attaque par déni de service (DoS) sur les réseaux informatiques.

#### Regardez les types d'attaques et leur proportion. Pensez-vous que ce dataset soit représentatif des mesures qu'on pourrait réaliser sur un réseau en 2021 ? Pensez-vous qu'il soit représentatif des attaques actuelles ?

Quelques autres attaques prononcées sont `neptune` (SYN Flood), `back` (TCP Reset ?). Enfin, il y a aussi la catégorie `normal`.

Le nombre d'attaques par déni de service semble trop élevé par rapport aux connexions normales. Cela me semble excessif, mais ce n'est pas surprenant vu le coût d'une attaque DoS.

## Question 3:

### Pouvez-vous identifier des attributs dont certaines valeurs vous paraissent très liées à certaines attaques ?

Après le split, j'ai trouvé le diagramme difficile à lire, donc j'ai regroupé les catégories avec l'outil `Edit Domain` pour reconstruire les catégories `normal`, `DOS`, `U2R`, `R2L` et `Probe`. J'ai utilisé ce [document](https://www.researchgate.net/figure/Attack-types-of-DoS-R2L-U2R-Probe-categories_tbl1_327110465) comme support pour cette transformation.

Je vais continuer le TP avec cette transformation appliquée.

Par exemple :
![](https://i.imgur.com/VqvuzUC.png)

Nous observons qu'un nombre élevé de `serror_rate` produit une forte probabilité d'une attaque de type DoS.

Un autre exemple :
![](https://i.imgur.com/g9NULUh.png)

Nous observons qu'un taux élevé de `rerror_rate` à partir d'un certain seuil est fortement corrélé à une attaque de type Probe.

## Question 4:

Listez les cinq attributs les plus corrélés aux attaques d'après leur `Gini coefficient`.
![](https://i.imgur.com/j0P5OWx.png)

Ceci nous permet d'identifier les cinq attributs les plus corrélés aux attaques.

### Question 5:

Quelle attaque précisément semble détectable avec cet attribut ?
Prenons l'exemple de `dst_bytes` :
![](https://i.imgur.com/JyxzgZ6.png)

Nous observons qu'un taux très faible de cet attribut est corrélé avec une attaque de type DoS, tandis qu'un taux élevé correspond plutôt à une attaque de type R2L.

De même pour l'attribut `count` :
![](https://i.imgur.com/68GDBHa.png)

À partir d'un certain seuil, c'est probablement une attaque.

## Question 6:

Vu que mon jeu de données est différent, je ne peux pas créer un arbre binaire pour l'erreur suivante :
![](https://i.imgur.com/p537RDl.png)

Continuons avec un arbre normal.

### Une capture pour la visualisation de l'arbre

L'arbre est gigantesque, voici une [image](https://i.imgur.com/VYaKWFs.png) que vous pouvez agrandir pour voir les détails.
![](https://i.imgur.com/VYaKWFs.png)

### Une autre capture pour la visualisation des règles de décisions.

![](https://i.imgur.com/LZuzVId.png)

## Question 7:

### Pourriez-vous, à partir de l'arbre de décision appris, donner un exemple d'instance qui serait prédit comme une attaque `Probe`

![](https://i.imgur.com/38fulWJ.png)

- Si `count` >= 65 et `service` = nntp ou vmnet, l'arbre prédit `Probe`.

### Même question avec les règles apprises

Voici quelques règles apprises qui prédisent avec une très forte probabilité une attaque de type `Probe` :
![](https://i.imgur.com/0jglEVw.png)

## Question 8:

### Pour chaque modèle, Quel est l'accuracy de ce modèle ?

La valeur de l'accuracy est présente sous le champ CA.
![](https://i.imgur.com/JVquenF.png)

### Pour chaque modèle, Combien y a-t-il de faux positifs ? (instances normales considérées comme attaques) De faux négatifs ? (attaques considérées comme normales)

Pour cette question, on fixe le `target` à `normal`.
![](https://i.imgur.com/H60Kwu4.png)

Un faux positif `fp'` dans cette image représente le cas où le trafic est malveillant mais détecté comme normal. Donc `fp'` = `fn`.

Un faux négatif `fn'` dans cette image représente le cas où le trafic est normal, mais détecté comme malveillant. Donc `fn'` = `fp`.

On aura aussi besoin du nombre total d'échantillons `N = 494021` et normaux `Nnorm = 97278`.

##### Faux positifs

La formule du `recall` s'écrit `r' = tp' / (tp' + fn')`. On rappelle que `tp' + fn'` correspond au nombre total des paquets normaux. Donc `Nnorm = tp' + fn'`.

On peut en déduire le nombre de faux positifs par `fp = fn' = (1 - r')*Nnorm`.

| Modèle                      | kNN | Tree | Random Forest | CN2 Rule Inducer |
| --------------------------- | --- | ---- | ------------- | ---------------- |
| **Nombre de faux positifs** | 97  | 973  | < 97          | 97               |

##### Faux négatifs

La formule du `accuracy` s'écrit `a' = (tp' + tn') / N`, ainsi `fp' + fn' = N * (1 - a')`.

Comme on a calculé `fn'` dans l'étape précédente, on peut maintenant en déduire le nombre de faux négatifs `fn = fp' = N*(1 - a') - fn'`.

| Modèle                      | kNN | Tree | Random Forest | CN2 Rule Inducer |
| --------------------------- | --- | ---- | ------------- | ---------------- |
| **Nombre de faux négatifs** | 397 | 2979 | < 494         | < 382            |

<span style="color: red">
C'est surprenant d'avoir des 0 ou des nombres négatifs, mais il peut y avoir des réels < <code>10<sup>-3</sup></code> qui ne sont pas affichés sous le champ Accuracy et Recall. J'ai remplacé ces instances par une borne supérieure.
</span>

### En supposant dix connexions légitimes par seconde, combien y aurait-il de faux positifs par jour en moyenne ? Trouvez-vous ce résultat satisfaisant pour une utilisation réelle ?

Pour chaque algorithme, on calcule le `False Positive Rate (FPR) = FP / P`.

Le nombre de faux positifs par jour est ainsi `FPR * 10 * 60*60*24`.

On obtient les valeurs suivantes :

| Modèle                               | kNN | Tree | Random Forest | CN2 Rule Inducer |
| ------------------------------------ | --- | ---- | ------------- | ---------------- |
| **Nombre de faux positifs par jour** | 861 | 8641 | < 84          | 861              |

Sauf pour `Random Forest`, le nombre de fausses alertes reste un peu élevé mais pas excessif.
